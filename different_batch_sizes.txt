
256
VGGNN:          INFO:     forward(): before all convolutional layers, x.size      = torch.Size([16, 3, 256, 256])
VGGNN:          INFO:     forward(): after  all convolutional layers, x.size      = torch.Size([16, 3, 256, 256])
VGGNN:          INFO:     forward(): after  flatenning,                x.size        = torch.Size([16, 32768])
VGGNN:          INFO:     forward(): after  F.relu(self.fc1(output)), output.size = torch.Size([16, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc2(output)), output.size = torch.Size([16, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc3(output)), output.size = torch.Size([16, 6])
VGGNN:          INFO:     forward(): after  all fully connected layers, x.size    = torch.Size([16, 6])

128
VGGNN:          INFO:     forward(): before all convolutional layers, x.size      = torch.Size([16, 3, 128, 128])
VGGNN:          INFO:     forward(): after  all convolutional layers, x.size      = torch.Size([16, 3, 128, 128])
VGGNN:          INFO:     forward(): after  reshaping, x.size                     = torch.Size([16, 8192])
VGGNN:          INFO:     forward(): after  F.relu(self.fc1(output)), output.size = torch.Size([16, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc2(output)), output.size = torch.Size([16, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc3(output)), output.size = torch.Size([16, 6])
VGGNN:          INFO:     forward(): after  all fully connected layers, x.size    = torch.Size([16, 6])

64
VGGNN:          INFO:     forward(): before all convolutional layers, x.size      = torch.Size([16, 3, 64, 64])
VGGNN:          INFO:     forward(): after  all convolutional layers, x.size      = torch.Size([16, 3, 64, 64])
VGGNN:          INFO:     forward(): after  flatenning,                x.size        = torch.Size([16, 2048])
VGGNN:          INFO:     forward(): after  F.relu(self.fc1(output)), output.size = torch.Size([16, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc2(output)), output.size = torch.Size([16, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc3(output)), output.size = torch.Size([16, 6])
VGGNN:          INFO:     forward(): after  all fully connected layers, x.size    = torch.Size([16, 6])

32
VGGNN:          INFO:     forward(): before all convolutional layers, x.size      = torch.Size([16, 3, 32, 32])
VGGNN:          INFO:     forward(): after  all convolutional layers, x.size      = torch.Size([16, 3, 32, 32])
VGGNN:          INFO:     forward(): after  flatenning,                x.size        = torch.Size([16, 512])
VGGNN:          INFO:     forward(): after  F.relu(self.fc1(output)), output.size = torch.Size([16, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc2(output)), output.size = torch.Size([16, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc3(output)), output.size = torch.Size([16, 6])
VGGNN:          INFO:     forward(): after  all fully connected layers, x.size    = torch.Size([16, 6])

512
VGGNN:          INFO:     forward(): before all convolutional layers, x.size      = torch.Size([4, 3, 512, 512])
VGGNN:          INFO:     forward(): after  all convolutional layers, x.size      = torch.Size([4, 3, 512, 512])
VGGNN:          INFO:     forward(): after  flatenning,                x.size        = torch.Size([4, 131072])
VGGNN:          INFO:     forward(): after  F.relu(self.fc1(output)), output.size = torch.Size([4, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc2(output)), output.size = torch.Size([4, 4096])
VGGNN:          INFO:     forward(): after  F.relu(self.fc3(output)), output.size = torch.Size([4, 6])
VGGNN:          INFO:     forward(): after  all fully connected layers, x.size    = torch.Size([4, 6])


